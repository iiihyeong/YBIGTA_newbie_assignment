{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7fc1c619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import classification_report, average_precision_score, precision_recall_curve\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c241aabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로드 성공\n"
     ]
    }
   ],
   "source": [
    "# 1. 데이터 로드\n",
    "df = pd.read_csv(r'C:\\Users\\pc57\\Downloads\\creditcard\\creditcard.csv')\n",
    "print(\"데이터 로드 성공\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2b8f9898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2] 샘플링 후 데이터 개수: 10492\n",
      "Class\n",
      "0    10000\n",
      "1      492\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 2. 샘플링\n",
    "# 명세: 사기(1)는 유지, 정상(0)은 10,000개만 랜덤 샘플링\n",
    "fraud = df[df['Class'] == 1]\n",
    "normal = df[df['Class'] == 0]\n",
    "\n",
    "# 정상 데이터 10,000개 추출 (random_state=42)\n",
    "normal_sample = normal.sample(n=10000, random_state=42)\n",
    "\n",
    "# 두 데이터 합치기\n",
    "df_sampled = pd.concat([fraud, normal_sample])\n",
    "\n",
    "# 데이터 불균형 확인\n",
    "print(\"\\n[2] 샘플링 후 데이터 개수:\", len(df_sampled))\n",
    "print(df_sampled['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a6855657",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. 데이터 전처리 (Amount 표준화)\n",
    "scaler = StandardScaler()\n",
    "df_sampled['Amount_Scaled'] = scaler.fit_transform(df_sampled['Amount'].values.reshape(-1, 1))\n",
    "df_sampled = df_sampled.drop(['Amount', 'Time'], axis=1)\n",
    "\n",
    "X = df_sampled.drop('Class', axis=1)\n",
    "y = df_sampled['Class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9a48992f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[4] 분할 후 학습 데이터 비율:\n",
      "Class\n",
      "0    0.953056\n",
      "1    0.046944\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 4. 학습/테스트 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"\\n[4] 분할 후 학습 데이터 비율:\")\n",
    "print(y_train.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f1b09e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[5] SMOTE 적용 후 데이터 개수:\n",
      "{0: 7999, 1: 7999}\n"
     ]
    }
   ],
   "source": [
    "# 5. SMOTE 적용\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"\\n[5] SMOTE 적용 후 데이터 개수:\")\n",
    "print(pd.Series(y_train_res).value_counts().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c957ff0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지표 계산 메소드\n",
    "def get_best_threshold(model, X_test, y_test, name):\n",
    "    '''\n",
    "    데이터 샘플링(Under-sampling)과 SMOTE(Over-sampling)를 통해 클래스 불균형을 완화한 후, \n",
    "    성능을 극대화하기 위한 최적화(Optimization) 전략\n",
    "\n",
    "    임계값 조정 (Threshold Tuning)\n",
    "    Precision-Recall Curve를 분석하여 F1-score가 최대가 되는 최적의 임계값을 찾아냄\n",
    "    <- 학습 데이터는 SMOTE를 통해 1:1 비율이 되었으나, 테스트 데이터는 여전히 불균형(Imbalanced) 상태이기 때문\n",
    "    -> Precision(정밀도)와 Recall(재현율)의 트레이드오프(Trade-off) 관계를 고려\n",
    "\n",
    "    이후...+ 하이퍼파라미터 튜닝 (Criterion & Estimators) \n",
    "    불순도 지표를 Gini에서 Entropy로 변경하고, 트리의 개수(n_estimators)를 100개에서 300~500개로 늘람\n",
    "    -> Entropy는 클래스 불순도에 더 민감하게 반응\n",
    "    -> 트리 개수 증가는 과적합을 방지하고 일반화 성능을 높이는 데 기여\n",
    "\n",
    "    ++ 모델 고도화\n",
    "    최종 모델로 RandomForestClassifier 대신 ExtraTreesClassifier (Extremely Randomized Trees)를 선정\n",
    "    -> 변동성 감소, SMOTE 노이즈에 대한 강건성\n",
    "    '''\n",
    "    probs = model.predict_proba(X_test)[:, 1]\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_test, probs)\n",
    "    f1s = 2 * (precisions * recalls) / (precisions + recalls + 1e-10)\n",
    "    best_idx = np.argmax(f1s)\n",
    "    \n",
    "    # PR-AUC\n",
    "    pr_auc = average_precision_score(y_test, probs)\n",
    "    \n",
    "    print(f\"\\n>> [{name}] 성적표\")\n",
    "    print(f\"   PR-AUC Score: {pr_auc:.4f}\")\n",
    "    print(f\"   Best Threshold: {thresholds[best_idx]:.4f}\")\n",
    "    print(f\"   예상 F1: {f1s[best_idx]:.4f} (Precision: {precisions[best_idx]:.4f}, Recall: {recalls[best_idx]:.4f})\")\n",
    "    \n",
    "    # 리포트 출력용\n",
    "    preds = (probs >= thresholds[best_idx]).astype(int)\n",
    "    print(classification_report(y_test, preds))\n",
    "    return pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "02f17611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 학습 중...\n",
      "학습 완료!\n",
      "\n",
      ">> [ExtraTrees 하이퍼파라미터 + Threshold 조정] 성적표\n",
      "   PR-AUC Score: 0.9529\n",
      "   Best Threshold: 0.4920\n",
      "   예상 F1: 0.9305 (Precision: 0.9775, Recall: 0.8878)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      2001\n",
      "           1       0.98      0.89      0.93        98\n",
      "\n",
      "    accuracy                           0.99      2099\n",
      "   macro avg       0.99      0.94      0.96      2099\n",
      "weighted avg       0.99      0.99      0.99      2099\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9529187228152467"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et_final = ExtraTreesClassifier(\n",
    "    n_estimators=500, \n",
    "    criterion='entropy', \n",
    "    max_depth=None, \n",
    "    min_samples_split=2, \n",
    "    random_state=42, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"모델 학습 중...\")\n",
    "et_final.fit(X_train_res, y_train_res)\n",
    "print(\"학습 완료!\")\n",
    "\n",
    "# 결과 출력 함수 호출 (이름도 ExtraTrees로 변경)\n",
    "get_best_threshold(et_final, X_test, y_test, \"ExtraTrees 하이퍼파라미터 + Threshold 조정\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ybigta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
